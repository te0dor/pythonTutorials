{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "188318 rows for training set\n",
      "125546 rows for test set\n"
     ]
    }
   ],
   "source": [
    "#Import Data\n",
    "df_train = pd.read_csv(r\"C:\\Users\\piush\\Desktop\\Dataset\\Allstate\\train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\piush\\Desktop\\Dataset\\Allstate\\test.csv\")\n",
    "print ('data loaded')\n",
    "print (str(len(df_train))+\" rows for training set\")\n",
    "print (str(len(df_test))+\" rows for test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_outlier(points, thresh = 3.5):\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "    return modified_z_score > thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.columns.values[:-1]]\n",
    "df = df_train.append(df_test, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = []\n",
    "for col in df.columns.values:\n",
    "    if df[col].dtype == 'object':\n",
    "        cats.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cont = df.drop(cats, axis=1)\n",
    "df_cat = df[cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df_cont.columns.values:\n",
    "    if np.sum(df_cont[col].isnull()) > 50:\n",
    "        #print(\"Removing Column: {}\".format(col))\n",
    "        df_cont = df_cont.drop(col, axis = 1)\n",
    "    elif np.sum(df_cont[col].isnull()) > 0:\n",
    "        #print(\"Replacing with Median: {}\".format(col))\n",
    "        median = df_cont[col].median()\n",
    "        idx = np.where(df_cont[col].isnull())[0]\n",
    "        df_cont[col].iloc[idx] = median\n",
    "        \n",
    "        \n",
    "        outliers = np.where(is_outlier(df_cont[col]))\n",
    "        df_cont[col].iloc[outliers] = median\n",
    "        \n",
    "               \n",
    "        if skew(df_cont[col]) > 0.75:\n",
    "            #print(\"Skewness Detected: {}\".format(col))\n",
    "            df_cont[col] = np.log(df_cont[col])\n",
    "            df_cont[col] = df_cont[col].apply(lambda x: 0 if x == -np.inf else x)\n",
    "        \n",
    "        df_cont[col] = Normalizer().fit_transform(df_cont[col].reshape(1,-1))[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "for col in df_cat.columns.values:\n",
    "    if np.sum(df_cat[col].isnull()) > 50:\n",
    "        df_cat = df_cat.drop(col, axis = 1)\n",
    "        continue\n",
    "    elif np.sum(df_cat[col].isnull()) > 0:\n",
    "        df_cat[col] = df_cat[col].fillna('MIA')\n",
    "        \n",
    "    df_cat[col] = LabelEncoder().fit_transform(df_cat[col])\n",
    "    \n",
    "    num_cols = df_cat[col].max()\n",
    "    for i in range(num_cols):\n",
    "        col_name = col + '_' + str(i)\n",
    "        df_cat[col_name] = df_cat[col].apply(lambda x: 1 if x == i else 0)\n",
    "        \n",
    "    df_cat = df_cat.drop(col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c0a6607dc0c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_log' is not defined"
     ]
    }
   ],
   "source": [
    "df_new = df_cont.join(df_cat)\n",
    "\n",
    "df_train = df_new.iloc[:len(df_train) - 1]\n",
    "df_train = df_train.join(target_log)\n",
    "\n",
    "df_test = df_new.iloc[len(df_train) + 1:]\n",
    "\n",
    "X_train = df_train[df_train.columns.values[1:-1]]\n",
    "y_train = df_train[df_train.columns.values[-1]]\n",
    "\n",
    "X_test = df_test[df_test.columns.values[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
