{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'C:\\Users\\piush\\Desktop\\Dataset\\RedHat\\act_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(r'C:\\Users\\piush\\Desktop\\Dataset\\RedHat\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_people = pd.read_csv(r'C:\\Users\\piush\\Desktop\\Dataset\\RedHat\\people.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas - Cleaning data We then review a selection of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%pylab inline\n",
    "\n",
    "# Set the global default size of matplotlib figures\n",
    "plt.rc('figure', figsize=(10, 5))\n",
    "# Size of matplotlib figures that contain subplots\n",
    "fizsize_with_subplots = (10, 10)\n",
    "# Size of matplotlib histogram bins\n",
    "bin_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_1734928</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_2434093</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_3404049</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_3651215</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_4109017</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  people_id   activity_id        date activity_category char_1 char_2 char_3  \\\n",
       "0   ppl_100  act2_1734928  2023-08-26            type 4    NaN    NaN    NaN   \n",
       "1   ppl_100  act2_2434093  2022-09-27            type 2    NaN    NaN    NaN   \n",
       "2   ppl_100  act2_3404049  2022-09-27            type 2    NaN    NaN    NaN   \n",
       "3   ppl_100  act2_3651215  2023-08-04            type 2    NaN    NaN    NaN   \n",
       "4   ppl_100  act2_4109017  2023-08-26            type 2    NaN    NaN    NaN   \n",
       "\n",
       "  char_4 char_5 char_6 char_7 char_8 char_9  char_10  outcome  \n",
       "0    NaN    NaN    NaN    NaN    NaN    NaN  type 76        0  \n",
       "1    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
       "2    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
       "3    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
       "4    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>act1_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act1_100006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>act1_100050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>act1_100065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>act1_100068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_id  outcome\n",
       "0       act1_1        0\n",
       "1  act1_100006        0\n",
       "2  act1_100050        0\n",
       "3  act1_100065        0\n",
       "4  act1_100068        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>char_1</th>\n",
       "      <th>group_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>date</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>...</th>\n",
       "      <th>char_29</th>\n",
       "      <th>char_30</th>\n",
       "      <th>char_31</th>\n",
       "      <th>char_32</th>\n",
       "      <th>char_33</th>\n",
       "      <th>char_34</th>\n",
       "      <th>char_35</th>\n",
       "      <th>char_36</th>\n",
       "      <th>char_37</th>\n",
       "      <th>char_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>type 2</td>\n",
       "      <td>group 17304</td>\n",
       "      <td>type 2</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 3</td>\n",
       "      <td>type 11</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100002</td>\n",
       "      <td>type 2</td>\n",
       "      <td>group 8688</td>\n",
       "      <td>type 3</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>type 28</td>\n",
       "      <td>type 9</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 3</td>\n",
       "      <td>type 11</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppl_100003</td>\n",
       "      <td>type 2</td>\n",
       "      <td>group 33592</td>\n",
       "      <td>type 3</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>type 4</td>\n",
       "      <td>type 8</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 2</td>\n",
       "      <td>type 5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppl_100004</td>\n",
       "      <td>type 2</td>\n",
       "      <td>group 22593</td>\n",
       "      <td>type 3</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>type 40</td>\n",
       "      <td>type 25</td>\n",
       "      <td>type 9</td>\n",
       "      <td>type 4</td>\n",
       "      <td>type 16</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl_100006</td>\n",
       "      <td>type 2</td>\n",
       "      <td>group 6534</td>\n",
       "      <td>type 3</td>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>type 40</td>\n",
       "      <td>type 25</td>\n",
       "      <td>type 9</td>\n",
       "      <td>type 3</td>\n",
       "      <td>type 8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    people_id  char_1      group_1  char_2        date   char_3   char_4  \\\n",
       "0     ppl_100  type 2  group 17304  type 2  2021-06-29   type 5   type 5   \n",
       "1  ppl_100002  type 2   group 8688  type 3  2021-01-06  type 28   type 9   \n",
       "2  ppl_100003  type 2  group 33592  type 3  2022-06-10   type 4   type 8   \n",
       "3  ppl_100004  type 2  group 22593  type 3  2022-07-20  type 40  type 25   \n",
       "4  ppl_100006  type 2   group 6534  type 3  2022-07-27  type 40  type 25   \n",
       "\n",
       "   char_5  char_6   char_7   ...   char_29 char_30 char_31 char_32 char_33  \\\n",
       "0  type 5  type 3  type 11   ...     False    True    True   False   False   \n",
       "1  type 5  type 3  type 11   ...     False    True    True    True    True   \n",
       "2  type 5  type 2   type 5   ...     False   False    True    True    True   \n",
       "3  type 9  type 4  type 16   ...      True    True    True    True    True   \n",
       "4  type 9  type 3   type 8   ...     False   False    True   False   False   \n",
       "\n",
       "  char_34 char_35 char_36 char_37 char_38  \n",
       "0    True    True    True   False      36  \n",
       "1    True    True    True   False      76  \n",
       "2    True   False    True    True      99  \n",
       "3    True    True    True    True      76  \n",
       "4   False    True    True   False      84  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_people.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------\n",
      "TRAIN SET INFORMATION\n",
      "---------------------\n",
      "Shape of training set: (2197291, 15) \n",
      "\n",
      "Column Headers: ['people_id', 'activity_id', 'date', 'activity_category', 'char_1', 'char_2', 'char_3', 'char_4', 'char_5', 'char_6', 'char_7', 'char_8', 'char_9', 'char_10', 'outcome'] \n",
      "\n",
      "people_id            object\n",
      "activity_id          object\n",
      "date                 object\n",
      "activity_category    object\n",
      "char_1               object\n",
      "char_2               object\n",
      "char_3               object\n",
      "char_4               object\n",
      "char_5               object\n",
      "char_6               object\n",
      "char_7               object\n",
      "char_8               object\n",
      "char_9               object\n",
      "char_10              object\n",
      "outcome               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Review input features\n",
    "print (\"\\n\\n---------------------\")\n",
    "print (\"TRAIN SET INFORMATION\")\n",
    "print (\"---------------------\")\n",
    "print (\"Shape of training set:\", df_train.shape, \"\\n\")\n",
    "print (\"Column Headers:\", list(df_train.columns.values), \"\\n\")\n",
    "print (df_train.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING SET INFORMATION\n",
      "========================\n",
      "\n",
      "'people_id' has 151295 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['ppl_100' 'ppl_100002' 'ppl_100003' 'ppl_100006' 'ppl_100013' 'ppl_100019'\n",
      " 'ppl_100025' 'ppl_100028' 'ppl_100029' 'ppl_100032']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'activity_id' has 2197291 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['act2_1734928' 'act2_2434093' 'act2_3404049' 'act2_3651215' 'act2_4109017'\n",
      " 'act2_898576' 'act2_1233489' 'act2_1623405' 'act2_1111598' 'act2_1177453']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'date' has 411 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['2023-08-26' '2022-09-27' '2023-08-04' '2022-11-23' '2023-02-07'\n",
      " '2023-06-28' '2022-08-10' '2023-03-02' '2022-09-13' '2023-02-10']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'activity_category' has 7 unique values\n",
      "['type 4' 'type 2' 'type 3' 'type 5' 'type 1' 'type 7' 'type 6']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_1' has 52 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[nan 'type 3' 'type 36' 'type 24' 'type 2' 'type 5' 'type 12' 'type 23'\n",
      " 'type 7' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_2' has 33 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[nan 'type 5' 'type 11' 'type 6' 'type 2' 'type 1' 'type 16' 'type 14'\n",
      " 'type 4' 'type 8']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_3' has 12 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[nan 'type 1' 'type 5' 'type 6' 'type 3' 'type 7' 'type 8' 'type 4'\n",
      " 'type 9' 'type 2']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_4' has 8 unique values\n",
      "[nan 'type 1' 'type 3' 'type 2' 'type 4' 'type 6' 'type 5' 'type 7']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_5' has 8 unique values\n",
      "[nan 'type 6' 'type 1' 'type 5' 'type 2' 'type 4' 'type 3' 'type 7']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_6' has 6 unique values\n",
      "[nan 'type 3' 'type 1' 'type 2' 'type 4' 'type 5']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_7' has 9 unique values\n",
      "[nan 'type 3' 'type 1' 'type 4' 'type 2' 'type 5' 'type 6' 'type 7'\n",
      " 'type 8']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_8' has 19 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[nan 'type 6' 'type 4' 'type 5' 'type 9' 'type 18' 'type 14' 'type 7'\n",
      " 'type 3' 'type 8']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_9' has 20 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[nan 'type 8' 'type 1' 'type 2' 'type 7' 'type 13' 'type 9' 'type 15'\n",
      " 'type 4' 'type 6']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_10' has 6516 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['type 76' 'type 1' 'type 1727' 'type 894' 'type 143' 'type 297' 'type 269'\n",
      " 'type 230' 'type 276' 'type 503']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'outcome' has 2 unique values\n",
      "[0 1]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Features with missing values:\n",
      "['char_1 has 2039676 missing', 'char_2 has 2039676 missing', 'char_3 has 2039676 missing', 'char_4 has 2039676 missing', 'char_5 has 2039676 missing', 'char_6 has 2039676 missing', 'char_7 has 2039676 missing', 'char_8 has 2039676 missing', 'char_9 has 2039676 missing', 'char_10 has 157615 missing']\n",
      "\n",
      "\n",
      "Features with non-numeric values:\n",
      "['people_id', 'activity_id', 'date', 'activity_category', 'char_1', 'char_2', 'char_3', 'char_4', 'char_5', 'char_6', 'char_7', 'char_8', 'char_9', 'char_10']\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "missing_values = []\n",
    "nonumeric_values = []\n",
    "\n",
    "print (\"TRAINING SET INFORMATION\")\n",
    "print (\"========================\\n\")\n",
    "\n",
    "for column in df_train:\n",
    "    # Find all the unique feature values\n",
    "    uniq = df_train[column].unique()\n",
    "    print (\"'{}' has {} unique values\" .format(column,uniq.size))\n",
    "    if (uniq.size > 10):\n",
    "        print(\"~~Listing up to 10 unique values~~\")\n",
    "    print (uniq[0:10])\n",
    "    print (\"\\n-----------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Find features with missing values\n",
    "    if (True in pd.isnull(uniq)):\n",
    "        s = \"{} has {} missing\" .format(column, pd.isnull(df_train[column]).sum())\n",
    "        missing_values.append(s)\n",
    "    \n",
    "    # Find features with non-numeric values\n",
    "    for i in range (1, np.prod(uniq.shape)):\n",
    "        if (re.match('nan', str(uniq[i]))):\n",
    "            break\n",
    "        if not (re.search('(^\\d+\\.?\\d*$)|(^\\d*\\.?\\d+$)', str(uniq[i]))):\n",
    "            nonumeric_values.append(column)\n",
    "            break\n",
    "  \n",
    "print (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "print (\"Features with missing values:\\n{}\\n\\n\" .format(missing_values))\n",
    "print (\"Features with non-numeric values:\\n{}\" .format(nonumeric_values))\n",
    "print (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we have 2197291 rows and 15 columns.\n",
    "All the data is categorical except the outcome which contains yes and no . \n",
    "According to submission file , we only need activity_id and outcome.\n",
    "in the dataset, people_id' has 151295 unique values and no missing values, therefore approximately 14.5 activity_id is associated with each person. There are 7 different types of activities.\n",
    "All corresponding activity characteristics have 2039676 missing values except char_10 .\n",
    "Each row in the activity file represents a unique activity performed by a person on a certain date. \n",
    "\n",
    "Type 1 activities are different from type 2-7 activities because there are more known characteristics associated with type 1 activities (nine in total) than type 2-7 activities (which have only one associated characteristic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------\n",
      "PEOPLE SET INFORMATION\n",
      "---------------------\n",
      "Shape of training set: (189118, 41) \n",
      "\n",
      "Column Headers: ['people_id', 'char_1', 'group_1', 'char_2', 'date', 'char_3', 'char_4', 'char_5', 'char_6', 'char_7', 'char_8', 'char_9', 'char_10', 'char_11', 'char_12', 'char_13', 'char_14', 'char_15', 'char_16', 'char_17', 'char_18', 'char_19', 'char_20', 'char_21', 'char_22', 'char_23', 'char_24', 'char_25', 'char_26', 'char_27', 'char_28', 'char_29', 'char_30', 'char_31', 'char_32', 'char_33', 'char_34', 'char_35', 'char_36', 'char_37', 'char_38'] \n",
      "\n",
      "people_id    object\n",
      "char_1       object\n",
      "group_1      object\n",
      "char_2       object\n",
      "date         object\n",
      "char_3       object\n",
      "char_4       object\n",
      "char_5       object\n",
      "char_6       object\n",
      "char_7       object\n",
      "char_8       object\n",
      "char_9       object\n",
      "char_10        bool\n",
      "char_11        bool\n",
      "char_12        bool\n",
      "char_13        bool\n",
      "char_14        bool\n",
      "char_15        bool\n",
      "char_16        bool\n",
      "char_17        bool\n",
      "char_18        bool\n",
      "char_19        bool\n",
      "char_20        bool\n",
      "char_21        bool\n",
      "char_22        bool\n",
      "char_23        bool\n",
      "char_24        bool\n",
      "char_25        bool\n",
      "char_26        bool\n",
      "char_27        bool\n",
      "char_28        bool\n",
      "char_29        bool\n",
      "char_30        bool\n",
      "char_31        bool\n",
      "char_32        bool\n",
      "char_33        bool\n",
      "char_34        bool\n",
      "char_35        bool\n",
      "char_36        bool\n",
      "char_37        bool\n",
      "char_38       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Review input features\n",
    "print (\"\\n\\n---------------------\")\n",
    "print (\"PEOPLE SET INFORMATION\")\n",
    "print (\"---------------------\")\n",
    "print (\"Shape of training set:\", df_people.shape, \"\\n\")\n",
    "print (\"Column Headers:\", list(df_people.columns.values), \"\\n\")\n",
    "print (df_people.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEOPLE SET INFORMATION\n",
      "========================\n",
      "\n",
      "'people_id' has 189118 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['ppl_100' 'ppl_100002' 'ppl_100003' 'ppl_100004' 'ppl_100006' 'ppl_10001'\n",
      " 'ppl_100010' 'ppl_100013' 'ppl_100019' 'ppl_100025']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_1' has 2 unique values\n",
      "['type 2' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'group_1' has 34224 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['group 17304' 'group 8688' 'group 33592' 'group 22593' 'group 6534'\n",
      " 'group 25417' 'group 4204' 'group 45749' 'group 36096' 'group 18035']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_2' has 3 unique values\n",
      "['type 2' 'type 3' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'date' has 1196 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['2021-06-29' '2021-01-06' '2022-06-10' '2022-07-20' '2022-07-27'\n",
      " '2022-10-14' '2022-09-01' '2023-01-24' '2023-03-26' '2022-08-26']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_3' has 43 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['type 5' 'type 28' 'type 4' 'type 40' 'type 6' 'type 8' 'type 14' 'type 7'\n",
      " 'type 10' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_4' has 25 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['type 5' 'type 9' 'type 8' 'type 25' 'type 6' 'type 7' 'type 10' 'type 1'\n",
      " 'type 12' 'type 2']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_5' has 9 unique values\n",
      "['type 5' 'type 9' 'type 4' 'type 8' 'type 7' 'type 6' 'type 1' 'type 2'\n",
      " 'type 3']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_6' has 7 unique values\n",
      "['type 3' 'type 2' 'type 4' 'type 1' 'type 6' 'type 5' 'type 7']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_7' has 25 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['type 11' 'type 5' 'type 16' 'type 8' 'type 1' 'type 7' 'type 9' 'type 20'\n",
      " 'type 2' 'type 17']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_8' has 8 unique values\n",
      "['type 2' 'type 1' 'type 3' 'type 6' 'type 8' 'type 5' 'type 4' 'type 7']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_9' has 9 unique values\n",
      "['type 2' 'type 4' 'type 1' 'type 3' 'type 6' 'type 8' 'type 5' 'type 9'\n",
      " 'type 7']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_10' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_11' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_12' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_13' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_14' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_15' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_16' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_17' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_18' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_19' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_20' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_21' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_22' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_23' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_24' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_25' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_26' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_27' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_28' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_29' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_30' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_31' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_32' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_33' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_34' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_35' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_36' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_37' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_38' has 101 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[ 36  76  99  84  90   2  91   0  60 100]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Features with missing values:\n",
      "[]\n",
      "\n",
      "\n",
      "Features with non-numeric values:\n",
      "['people_id', 'char_1', 'group_1', 'char_2', 'date', 'char_3', 'char_4', 'char_5', 'char_6', 'char_7', 'char_8', 'char_9', 'char_10', 'char_11', 'char_12', 'char_13', 'char_14', 'char_15', 'char_16', 'char_17', 'char_18', 'char_19', 'char_20', 'char_21', 'char_22', 'char_23', 'char_24', 'char_25', 'char_26', 'char_27', 'char_28', 'char_29', 'char_30', 'char_31', 'char_32', 'char_33', 'char_34', 'char_35', 'char_36', 'char_37']\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "missing_values = []\n",
    "nonumeric_values = []\n",
    "\n",
    "print (\"PEOPLE SET INFORMATION\")\n",
    "print (\"========================\\n\")\n",
    "\n",
    "for column in df_people:\n",
    "    # Find all the unique feature values\n",
    "    uniq = df_people[column].unique()\n",
    "    print (\"'{}' has {} unique values\" .format(column,uniq.size))\n",
    "    if (uniq.size > 10):\n",
    "        print(\"~~Listing up to 10 unique values~~\")\n",
    "    print (uniq[0:10])\n",
    "    print (\"\\n-----------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Find features with missing values\n",
    "    if (True in pd.isnull(uniq)):\n",
    "        s = \"{} has {} missing\" .format(column, pd.isnull(df_people[column]).sum())\n",
    "        missing_values.append(s)\n",
    "    \n",
    "    # Find features with non-numeric values\n",
    "    for i in range (1, np.prod(uniq.shape)):\n",
    "        if (re.match('nan', str(uniq[i]))):\n",
    "            break\n",
    "        if not (re.search('(^\\d+\\.?\\d*$)|(^\\d*\\.?\\d+$)', str(uniq[i]))):\n",
    "            nonumeric_values.append(column)\n",
    "            break\n",
    "  \n",
    "print (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "print (\"Features with missing values:\\n{}\\n\\n\" .format(missing_values))\n",
    "print (\"Features with non-numeric values:\\n{}\" .format(nonumeric_values))\n",
    "print (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we have 189118 rows and 41 columns.\n",
    "\n",
    "There are no missing values. \n",
    "The two files can be joined together using people_id as the common key. So we have more people_id in the people file than \n",
    "\n",
    "All variables are categorical, with the exception of 'char_38' in the people file, which is a continuous numerical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us merge the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date_x</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1_x</th>\n",
       "      <th>char_2_x</th>\n",
       "      <th>char_3_x</th>\n",
       "      <th>char_4_x</th>\n",
       "      <th>char_5_x</th>\n",
       "      <th>char_6_x</th>\n",
       "      <th>...</th>\n",
       "      <th>char_29</th>\n",
       "      <th>char_30</th>\n",
       "      <th>char_31</th>\n",
       "      <th>char_32</th>\n",
       "      <th>char_33</th>\n",
       "      <th>char_34</th>\n",
       "      <th>char_35</th>\n",
       "      <th>char_36</th>\n",
       "      <th>char_37</th>\n",
       "      <th>char_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_1734928</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_2434093</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_3404049</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_3651215</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_4109017</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  people_id   activity_id      date_x activity_category char_1_x char_2_x  \\\n",
       "0   ppl_100  act2_1734928  2023-08-26            type 4      NaN      NaN   \n",
       "1   ppl_100  act2_2434093  2022-09-27            type 2      NaN      NaN   \n",
       "2   ppl_100  act2_3404049  2022-09-27            type 2      NaN      NaN   \n",
       "3   ppl_100  act2_3651215  2023-08-04            type 2      NaN      NaN   \n",
       "4   ppl_100  act2_4109017  2023-08-26            type 2      NaN      NaN   \n",
       "\n",
       "  char_3_x char_4_x char_5_x char_6_x   ...   char_29 char_30 char_31 char_32  \\\n",
       "0      NaN      NaN      NaN      NaN   ...     False    True    True   False   \n",
       "1      NaN      NaN      NaN      NaN   ...     False    True    True   False   \n",
       "2      NaN      NaN      NaN      NaN   ...     False    True    True   False   \n",
       "3      NaN      NaN      NaN      NaN   ...     False    True    True   False   \n",
       "4      NaN      NaN      NaN      NaN   ...     False    True    True   False   \n",
       "\n",
       "   char_33 char_34 char_35 char_36 char_37 char_38  \n",
       "0    False    True    True    True   False      36  \n",
       "1    False    True    True    True   False      36  \n",
       "2    False    True    True    True   False      36  \n",
       "3    False    True    True    True   False      36  \n",
       "4    False    True    True    True   False      36  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins\n",
    "\n",
    "#A left join will preserve the records of the \"left\" table.\n",
    "\n",
    "df = pd.merge(df_train, df_people, on='people_id', how='left')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------\n",
      "SET INFORMATION\n",
      "---------------------\n",
      "Shape of training set: (2197291, 55) \n",
      "\n",
      "Column Headers: ['people_id', 'activity_id', 'date_x', 'activity_category', 'char_1_x', 'char_2_x', 'char_3_x', 'char_4_x', 'char_5_x', 'char_6_x', 'char_7_x', 'char_8_x', 'char_9_x', 'char_10_x', 'outcome', 'char_1_y', 'group_1', 'char_2_y', 'date_y', 'char_3_y', 'char_4_y', 'char_5_y', 'char_6_y', 'char_7_y', 'char_8_y', 'char_9_y', 'char_10_y', 'char_11', 'char_12', 'char_13', 'char_14', 'char_15', 'char_16', 'char_17', 'char_18', 'char_19', 'char_20', 'char_21', 'char_22', 'char_23', 'char_24', 'char_25', 'char_26', 'char_27', 'char_28', 'char_29', 'char_30', 'char_31', 'char_32', 'char_33', 'char_34', 'char_35', 'char_36', 'char_37', 'char_38'] \n",
      "\n",
      "people_id            object\n",
      "activity_id          object\n",
      "date_x               object\n",
      "activity_category    object\n",
      "char_1_x             object\n",
      "char_2_x             object\n",
      "char_3_x             object\n",
      "char_4_x             object\n",
      "char_5_x             object\n",
      "char_6_x             object\n",
      "char_7_x             object\n",
      "char_8_x             object\n",
      "char_9_x             object\n",
      "char_10_x            object\n",
      "outcome               int64\n",
      "char_1_y             object\n",
      "group_1              object\n",
      "char_2_y             object\n",
      "date_y               object\n",
      "char_3_y             object\n",
      "char_4_y             object\n",
      "char_5_y             object\n",
      "char_6_y             object\n",
      "char_7_y             object\n",
      "char_8_y             object\n",
      "char_9_y             object\n",
      "char_10_y              bool\n",
      "char_11                bool\n",
      "char_12                bool\n",
      "char_13                bool\n",
      "char_14                bool\n",
      "char_15                bool\n",
      "char_16                bool\n",
      "char_17                bool\n",
      "char_18                bool\n",
      "char_19                bool\n",
      "char_20                bool\n",
      "char_21                bool\n",
      "char_22                bool\n",
      "char_23                bool\n",
      "char_24                bool\n",
      "char_25                bool\n",
      "char_26                bool\n",
      "char_27                bool\n",
      "char_28                bool\n",
      "char_29                bool\n",
      "char_30                bool\n",
      "char_31                bool\n",
      "char_32                bool\n",
      "char_33                bool\n",
      "char_34                bool\n",
      "char_35                bool\n",
      "char_36                bool\n",
      "char_37                bool\n",
      "char_38               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Review input features\n",
    "print (\"\\n\\n---------------------\")\n",
    "print (\"SET INFORMATION\")\n",
    "print (\"---------------------\")\n",
    "print (\"Shape of training set:\", df.shape, \"\\n\")\n",
    "print (\"Column Headers:\", list(df.columns.values), \"\\n\")\n",
    "print (df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET INFORMATION\n",
      "========================\n",
      "\n",
      "'people_id' has 151295 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['ppl_100' 'ppl_100002' 'ppl_100003' 'ppl_100006' 'ppl_100013' 'ppl_100019'\n",
      " 'ppl_100025' 'ppl_100028' 'ppl_100029' 'ppl_100032']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'activity_id' has 2197291 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['act2_1734928' 'act2_2434093' 'act2_3404049' 'act2_3651215' 'act2_4109017'\n",
      " 'act2_898576' 'act2_1233489' 'act2_1623405' 'act2_1111598' 'act2_1177453']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'date_x' has 411 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['2023-08-26' '2022-09-27' '2023-08-04' '2022-11-23' '2023-02-07'\n",
      " '2023-06-28' '2022-08-10' '2023-03-02' '2022-09-13' '2023-02-10']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'activity_category' has 7 unique values\n",
      "['type 4' 'type 2' 'type 3' 'type 5' 'type 1' 'type 7' 'type 6']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_1_x' has 52 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[nan 'type 3' 'type 36' 'type 24' 'type 2' 'type 5' 'type 12' 'type 23'\n",
      " 'type 7' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_2_x' has 33 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[nan 'type 5' 'type 11' 'type 6' 'type 2' 'type 1' 'type 16' 'type 14'\n",
      " 'type 4' 'type 8']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_3_x' has 12 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[nan 'type 1' 'type 5' 'type 6' 'type 3' 'type 7' 'type 8' 'type 4'\n",
      " 'type 9' 'type 2']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_4_x' has 8 unique values\n",
      "[nan 'type 1' 'type 3' 'type 2' 'type 4' 'type 6' 'type 5' 'type 7']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_5_x' has 8 unique values\n",
      "[nan 'type 6' 'type 1' 'type 5' 'type 2' 'type 4' 'type 3' 'type 7']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_6_x' has 6 unique values\n",
      "[nan 'type 3' 'type 1' 'type 2' 'type 4' 'type 5']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_7_x' has 9 unique values\n",
      "[nan 'type 3' 'type 1' 'type 4' 'type 2' 'type 5' 'type 6' 'type 7'\n",
      " 'type 8']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_8_x' has 19 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[nan 'type 6' 'type 4' 'type 5' 'type 9' 'type 18' 'type 14' 'type 7'\n",
      " 'type 3' 'type 8']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_9_x' has 20 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[nan 'type 8' 'type 1' 'type 2' 'type 7' 'type 13' 'type 9' 'type 15'\n",
      " 'type 4' 'type 6']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_10_x' has 6516 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['type 76' 'type 1' 'type 1727' 'type 894' 'type 143' 'type 297' 'type 269'\n",
      " 'type 230' 'type 276' 'type 503']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'outcome' has 2 unique values\n",
      "[0 1]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_1_y' has 2 unique values\n",
      "['type 2' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'group_1' has 29899 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['group 17304' 'group 8688' 'group 33592' 'group 6534' 'group 4204'\n",
      " 'group 45749' 'group 36096' 'group 18035' 'group 9439' 'group 19662']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_2_y' has 3 unique values\n",
      "['type 2' 'type 3' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'date_y' has 1196 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['2021-06-29' '2021-01-06' '2022-06-10' '2022-07-27' '2023-01-24'\n",
      " '2023-03-26' '2022-08-26' '2023-04-21' '2023-07-15' '2022-07-26']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_3_y' has 43 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['type 5' 'type 28' 'type 4' 'type 40' 'type 14' 'type 7' 'type 10'\n",
      " 'type 6' 'type 11' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_4_y' has 25 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['type 5' 'type 9' 'type 8' 'type 25' 'type 6' 'type 7' 'type 10' 'type 12'\n",
      " 'type 2' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_5_y' has 9 unique values\n",
      "['type 5' 'type 9' 'type 4' 'type 8' 'type 7' 'type 6' 'type 2' 'type 1'\n",
      " 'type 3']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_6_y' has 7 unique values\n",
      "['type 3' 'type 2' 'type 1' 'type 4' 'type 6' 'type 5' 'type 7']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_7_y' has 25 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "['type 11' 'type 5' 'type 8' 'type 7' 'type 9' 'type 20' 'type 2' 'type 17'\n",
      " 'type 23' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_8_y' has 8 unique values\n",
      "['type 2' 'type 3' 'type 6' 'type 8' 'type 5' 'type 4' 'type 7' 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_9_y' has 9 unique values\n",
      "['type 2' 'type 4' 'type 3' 'type 6' 'type 8' 'type 5' 'type 9' 'type 7'\n",
      " 'type 1']\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_10_y' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_11' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_12' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_13' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_14' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_15' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_16' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_17' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_18' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_19' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_20' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_21' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_22' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_23' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_24' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_25' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_26' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_27' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_28' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_29' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_30' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_31' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_32' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_33' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_34' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_35' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_36' has 2 unique values\n",
      "[True False]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_37' has 2 unique values\n",
      "[False True]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "'char_38' has 101 unique values\n",
      "~~Listing up to 10 unique values~~\n",
      "[ 36  76  99  84  91   0  60 100  68  67]\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Features with missing values:\n",
      "['char_1_x has 2039676 missing', 'char_2_x has 2039676 missing', 'char_3_x has 2039676 missing', 'char_4_x has 2039676 missing', 'char_5_x has 2039676 missing', 'char_6_x has 2039676 missing', 'char_7_x has 2039676 missing', 'char_8_x has 2039676 missing', 'char_9_x has 2039676 missing', 'char_10_x has 157615 missing']\n",
      "\n",
      "\n",
      "Features with non-numeric values:\n",
      "['people_id', 'activity_id', 'date_x', 'activity_category', 'char_1_x', 'char_2_x', 'char_3_x', 'char_4_x', 'char_5_x', 'char_6_x', 'char_7_x', 'char_8_x', 'char_9_x', 'char_10_x', 'char_1_y', 'group_1', 'char_2_y', 'date_y', 'char_3_y', 'char_4_y', 'char_5_y', 'char_6_y', 'char_7_y', 'char_8_y', 'char_9_y', 'char_10_y', 'char_11', 'char_12', 'char_13', 'char_14', 'char_15', 'char_16', 'char_17', 'char_18', 'char_19', 'char_20', 'char_21', 'char_22', 'char_23', 'char_24', 'char_25', 'char_26', 'char_27', 'char_28', 'char_29', 'char_30', 'char_31', 'char_32', 'char_33', 'char_34', 'char_35', 'char_36', 'char_37']\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_values = []\n",
    "nonumeric_values = []\n",
    "\n",
    "print (\"SET INFORMATION\")\n",
    "print (\"========================\\n\")\n",
    "\n",
    "for column in df:\n",
    "    # Find all the unique feature values\n",
    "    uniq = df[column].unique()\n",
    "    print (\"'{}' has {} unique values\" .format(column,uniq.size))\n",
    "    if (uniq.size > 10):\n",
    "        print(\"~~Listing up to 10 unique values~~\")\n",
    "    print (uniq[0:10])\n",
    "    print (\"\\n-----------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Find features with missing values\n",
    "    if (True in pd.isnull(uniq)):\n",
    "        s = \"{} has {} missing\" .format(column, pd.isnull(df[column]).sum())\n",
    "        missing_values.append(s)\n",
    "    \n",
    "    # Find features with non-numeric values\n",
    "    for i in range (1, np.prod(uniq.shape)):\n",
    "        if (re.match('nan', str(uniq[i]))):\n",
    "            break\n",
    "        if not (re.search('(^\\d+\\.?\\d*$)|(^\\d*\\.?\\d+$)', str(uniq[i]))):\n",
    "            nonumeric_values.append(column)\n",
    "            break\n",
    "  \n",
    "print (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "print (\"Features with missing values:\\n{}\\n\\n\" .format(missing_values))\n",
    "print (\"Features with non-numeric values:\\n{}\" .format(nonumeric_values))\n",
    "print (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>char_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.197291e+06</td>\n",
       "      <td>2.197291e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.439544e-01</td>\n",
       "      <td>4.998051e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.968491e-01</td>\n",
       "      <td>3.608557e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            outcome       char_38\n",
       "count  2.197291e+06  2.197291e+06\n",
       "mean   4.439544e-01  4.998051e+01\n",
       "std    4.968491e-01  3.608557e+01\n",
       "min    0.000000e+00  0.000000e+00\n",
       "25%    0.000000e+00  0.000000e+00\n",
       "50%    0.000000e+00  5.900000e+01\n",
       "75%    1.000000e+00  8.200000e+01\n",
       "max    1.000000e+00  1.000000e+02"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply drop the people_id,date_x,date_y,date_y,group_1 attribute, since we do not expect it to be informative about the outcome status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_1 = df.drop(['people_id','date_x','date_y','group_1'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the boolean to 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_1[['char_10_y','char_11','char_12','char_13','char_14','char_15','char_16','char_17','char_18','char_19','char_20','char_21','char_22','char_23','char_24','char_25','char_26','char_27','char_28','char_29','char_30',\n",
    "   'char_31','char_32','char_33','char_34','char_35','char_36','char_37']] = df_1[['char_10_y','char_11','char_12','char_13','char_14','char_15','char_16','char_17','char_18','char_19','char_20','char_21','char_22','char_23','char_24','char_25','char_26','char_27','char_28','char_29','char_30',\n",
    "   'char_31','char_32','char_33','char_34','char_35','char_36','char_37']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_columns = df_1.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['activity_id', 'activity_category', 'char_1_x', 'char_2_x', 'char_3_x',\n",
       "       'char_4_x', 'char_5_x', 'char_6_x', 'char_7_x', 'char_8_x', 'char_9_x',\n",
       "       'char_10_x', 'char_1_y', 'char_2_y', 'char_3_y', 'char_4_y', 'char_5_y',\n",
       "       'char_6_y', 'char_7_y', 'char_8_y', 'char_9_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### works only for Category\n",
    "df_1[cat_columns] = df_1[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_series_ids(x):\n",
    "    '''Function returns a pandas series consisting of ids, \n",
    "       corresponding to objects in input pandas series x\n",
    "       Example: \n",
    "       get_series_ids(pd.Series(['a','a','b','b','c'])) \n",
    "       returns Series([0,0,1,1,2], dtype=int)'''\n",
    "\n",
    "    values = np.unique(x)\n",
    "    values2nums = dict(zip(values,range(len(values))))\n",
    "    return x.replace(values2nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_1['activity_category'] = get_series_ids(df_1['activity_category'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### does not do the function. factorize is better\n",
    "from sklearn import preprocessing\n",
    "enc = preprocessing.LabelEncoder()\n",
    "mask = ~df_1['char_1_x'].isnull()\n",
    "enc.fit(df_1['char_1_x'][mask])\n",
    "print('fitting')\n",
    "df_1['char_1_x'][mask] = enc.transform(df_1['char_1_x'][mask])\n",
    "print('transforming')\n",
    "print(df_1['char_1_x'])\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_1['char_1_x'] = df_1['char_1_x'].astype(float).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1_x</th>\n",
       "      <th>char_2_x</th>\n",
       "      <th>char_3_x</th>\n",
       "      <th>char_4_x</th>\n",
       "      <th>char_5_x</th>\n",
       "      <th>char_6_x</th>\n",
       "      <th>char_7_x</th>\n",
       "      <th>char_8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>char_29</th>\n",
       "      <th>char_30</th>\n",
       "      <th>char_31</th>\n",
       "      <th>char_32</th>\n",
       "      <th>char_33</th>\n",
       "      <th>char_34</th>\n",
       "      <th>char_35</th>\n",
       "      <th>char_36</th>\n",
       "      <th>char_37</th>\n",
       "      <th>char_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_id  activity_category  char_1_x  char_2_x  char_3_x  char_4_x  \\\n",
       "0            0                  3      -1.0        -1        -1        -1   \n",
       "1            1                  1      -1.0        -1        -1        -1   \n",
       "2            2                  1      -1.0        -1        -1        -1   \n",
       "3            3                  1      -1.0        -1        -1        -1   \n",
       "4            4                  1      -1.0        -1        -1        -1   \n",
       "5            5                  3      -1.0        -1        -1        -1   \n",
       "6            6                  1      -1.0        -1        -1        -1   \n",
       "7            7                  1      -1.0        -1        -1        -1   \n",
       "8            8                  1      -1.0        -1        -1        -1   \n",
       "9            9                  1      -1.0        -1        -1        -1   \n",
       "\n",
       "   char_5_x  char_6_x  char_7_x  char_8_x   ...     char_29  char_30  char_31  \\\n",
       "0        -1        -1        -1        -1   ...           0        1        1   \n",
       "1        -1        -1        -1        -1   ...           0        1        1   \n",
       "2        -1        -1        -1        -1   ...           0        1        1   \n",
       "3        -1        -1        -1        -1   ...           0        1        1   \n",
       "4        -1        -1        -1        -1   ...           0        1        1   \n",
       "5        -1        -1        -1        -1   ...           0        1        1   \n",
       "6        -1        -1        -1        -1   ...           0        1        1   \n",
       "7        -1        -1        -1        -1   ...           0        1        1   \n",
       "8        -1        -1        -1        -1   ...           0        0        1   \n",
       "9        -1        -1        -1        -1   ...           0        0        1   \n",
       "\n",
       "   char_32  char_33  char_34  char_35  char_36  char_37  char_38  \n",
       "0        0        0        1        1        1        0       36  \n",
       "1        0        0        1        1        1        0       36  \n",
       "2        0        0        1        1        1        0       36  \n",
       "3        0        0        1        1        1        0       36  \n",
       "4        0        0        1        1        1        0       36  \n",
       "5        0        0        1        1        1        0       36  \n",
       "6        1        1        1        1        1        0       76  \n",
       "7        1        1        1        1        1        0       76  \n",
       "8        1        1        1        0        1        1       99  \n",
       "9        1        1        1        0        1        1       99  \n",
       "\n",
       "[10 rows x 51 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_1['char_2_x'] = df_1['char_2_x'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_3_x'] = df_1['char_3_x'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_4_x'] = df_1['char_4_x'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_5_x'] = df_1['char_5_x'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_6_x'] = df_1['char_6_x'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_7_x'] = df_1['char_7_x'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_8_x'] = df_1['char_8_x'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_9_x'] = df_1['char_9_x'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_10_x'] = df_1['char_10_x'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_1_y'] = df_1['char_1_y'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_2_y'] = df_1['char_2_y'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_3_y'] = df_1['char_3_y'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_4_y'] = df_1['char_4_y'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_5_y'] = df_1['char_5_y'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_6_y'] = df_1['char_6_y'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_7_y'] = df_1['char_7_y'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_8_y'] = df_1['char_8_y'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['char_9_y'] = df_1['char_9_y'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1['activity_id'] = df_1['activity_id'].factorize()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### get_dummies gives merrory error\n",
    "\n",
    "df_1_get_dummies = df_1[['activity_category','char_1_x','char_2_x','char_3_x','char_4_x','char_5_x',\n",
    "                                          'char_6_x','char_7_x','char_8_x','char_9_x','char_10_x','char_1_y','char_2_y','char_3_y',\n",
    "                                          'char_4_y','char_5_y','char_6_y','char_7_y','char_8_y','char_9_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ValueError: ('Unable to parse string', 'occurred at index activity_id')\n",
    "\n",
    "df_1 = df_1.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2197291 entries, 0 to 2197290\n",
      "Data columns (total 51 columns):\n",
      "activity_id          int32\n",
      "activity_category    int64\n",
      "char_1_x             int32\n",
      "char_2_x             int32\n",
      "char_3_x             int32\n",
      "char_4_x             int32\n",
      "char_5_x             int32\n",
      "char_6_x             int32\n",
      "char_7_x             int32\n",
      "char_8_x             int32\n",
      "char_9_x             int32\n",
      "char_10_x            int32\n",
      "outcome              int64\n",
      "char_1_y             int32\n",
      "char_2_y             int32\n",
      "char_3_y             int32\n",
      "char_4_y             int32\n",
      "char_5_y             int32\n",
      "char_6_y             int32\n",
      "char_7_y             int32\n",
      "char_8_y             int32\n",
      "char_9_y             int32\n",
      "char_10_y            int32\n",
      "char_11              int32\n",
      "char_12              int32\n",
      "char_13              int32\n",
      "char_14              int32\n",
      "char_15              int32\n",
      "char_16              int32\n",
      "char_17              int32\n",
      "char_18              int32\n",
      "char_19              int32\n",
      "char_20              int32\n",
      "char_21              int32\n",
      "char_22              int32\n",
      "char_23              int32\n",
      "char_24              int32\n",
      "char_25              int32\n",
      "char_26              int32\n",
      "char_27              int32\n",
      "char_28              int32\n",
      "char_29              int32\n",
      "char_30              int32\n",
      "char_31              int32\n",
      "char_32              int32\n",
      "char_33              int32\n",
      "char_34              int32\n",
      "char_35              int32\n",
      "char_36              int32\n",
      "char_37              int32\n",
      "char_38              int64\n",
      "dtypes: int32(48), int64(3)\n",
      "memory usage: 469.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "df_target = df_1['outcome']\n",
    "df_data = df_1.drop(['outcome'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data, df_target, test_size=0.25, random_state=33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "dt = dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, show_confussion_matrix=True):\n",
    "    y_pred = clf.predict(X)   \n",
    "    if show_accuracy:\n",
    "         print (\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y, y_pred)),\"\\n\")\n",
    "    if show_classification_report:\n",
    "        print (\"Classification report\")\n",
    "        print (metrics.classification_report(y, y_pred),\"\\n\")\n",
    "      \n",
    "    if show_confussion_matrix:\n",
    "        print (\"Confussion matrix\")\n",
    "        print (metrics.confusion_matrix(y, y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.968 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(X_test, y_test, dt, show_confussion_matrix=False, show_classification_report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-529d0a8dbd6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchi2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#X_train_fs = fs.fit_transform(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#print (df_data.columns[fs.get_support()])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py\u001b[0m in \u001b[0;36mchi2\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "#from sklearn import feature_selection\n",
    "#fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=20)\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X_train, y_train)\n",
    "#X_train_fs = fs.fit_transform(X_train, y_train)\n",
    "#print (df_data.columns[fs.get_support()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
