{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the pandas package, then use the \"read_csv\" function to read\n",
    "# the labeled training data\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "%config InlineBackend.figure_format = 'png' #set 'png' here when working on notebook\n",
    "warnings.filterwarnings('ignore') \n",
    "train = pd.read_csv(r\"C:\\Users\\piush\\Desktop\\Dataset\\HostelWorld\\train_review_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a small sample of 200 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = train.sample(n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select only review_language english\n",
    "\n",
    "df = df.loc[df['review_language'] == ('English')]\n",
    "df = df.set_index('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_text = df['review_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "The samples in the dataset should be preprocessed before performing any type of operation in it. The\n",
    "preprocessing includes\n",
    "1. Upper to lower case conversion:For the easiness of feature selection all the data should be converted into\n",
    "lower cases.\n",
    "2. Normalization:All words with apostrophizes should be replace with its original form. E.g. don’t-> do not.\n",
    "3. Non ASCII removal: All non ASCII characters are removed from the samples.\n",
    "4. Remove new lines: The datasets contains some unwanted new lines that are also removed before the feature\n",
    "selection phase.\n",
    "5. Remove unwanted punctuations: All punctuations should be removed before feature selection.\n",
    "5. Stop word removal: Stop words in the English language are “a”, “an”, “the”, “is”. We have removed all words whose length is less than 3, except no, not, none.To remove stop words we are using Natural\n",
    "Language Toolkit (NLTK)8provided by python.\n",
    "6. Stemming: We observed that some of the words in the dataset have similar roots but they may differ only in affixes For example: computer, computation, computing has same root comput. The main purpose of this step is that reducing the feature set and improves the classification performance. We are using Porter\n",
    "stemmer of NLTK provided by python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tokenisation\n",
    "import nltk\n",
    "\n",
    "df['df_text'] = df.apply(lambda row: nltk.word_tokenize(row['review_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['df_text_stop'] = df['df_text'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stemming is the process of reducing a word to its base/root form, called stem\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "df['stemmed'] = df[\"df_text_stop\"].apply(lambda x: [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "##### Unigram of words:\n",
    "We are performing some preprocessing on this feature such as stemming and stop word removal. So that we are\n",
    "considering different categories of unigram features such as unigram with stemming with stop word, unigram with\n",
    "stemming without stop words, unigram without stemming with stop words. We are not considering without\n",
    "stemming without stop words category because without stemming will cause high dimensional features, since it does\n",
    "not reduce to the root form of words. Also removal of stop words flips the negative samples to positive samples.\n",
    "\n",
    "##### Bigram of words:\n",
    "Like unigrams, we are considering two categories of Bigram such as Bigram without stemming with stop words\n",
    "and Bigram with stemming with stop words. Due to the high dimensionality of bigram features. We are considering\n",
    "features which are appearing more than three times in our dataset.\n",
    "\n",
    "#### Semantic Orientation\n",
    "First Step, we have to classify the set of\n",
    "positive terms and negative terms present in\n",
    "each trip advisor review. Secondly, the partof-\n",
    "speech tagger is applied to the review. Two consecutive words are\n",
    "extracted from the review if their tags\n",
    "conform to any of the patterns.\n",
    "\n",
    "The JJ tags indicate adjectives, the NN tags\n",
    "are nouns, the RB tags are adverbs, and the third word (which is not extracted) cannot\n",
    "be a noun. NNP and NNPS (singular and\n",
    "plural proper nouns) are avoided, so that\n",
    "the names of the items in the review\n",
    "cannot influence the classification.\n",
    "\n",
    "##### Parts of speech tags:\n",
    "We are considering 36 parts of speech tags such VB, PRP, DT, NN etc. Each text in the reviews will be tagged\n",
    "using POS tagger of NLTK9. \n",
    "\n",
    "###### The number of tags of reviews varies, since 36 tags are not used in this experiment.\n",
    "We have 26 tags and 25 tag in positive and negative class respectively.\n",
    "\n",
    "##### Function Words:\n",
    "Function words or grammatical words are the words that have little lexicalmeaning or have ambiguousmeanings.\n",
    "We are considering375 function words10.Tonormalize all these counts we are dividing the count by N (Total number\n",
    "of words).\n",
    "\n",
    "###### Word based features:\n",
    "We are usingeight statistical measures10exploring that whether the count of words in each samples, helps to\n",
    "extract the sentiments of review. By using these features we are exploring that whether the count of words in each\n",
    "samples, helps to extractthe sentiments of review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "##### Mutual Information (MI)\n",
    "MIterm selects features that are not uniformly distributed among the sentiment classes because they are\n",
    "informative of their classes. And we can see that MI giving more importance to the rare term.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Mutual_information\n",
    "\n",
    "\n",
    "##### Information gain(IG)\n",
    "Information gain is the most commonly used feature selection method in the field of machine learning. It\n",
    "calculates the relevance of a feature for prediction of sentiment of review by analysing the presence or absence of a\n",
    "feature in a document.\n",
    "https://en.wikipedia.org/wiki/Information_gain_ratio\n",
    "\n",
    "##### Chi-square ( λ2 )\n",
    "Chi-squaremeasures how much expected counts and observed counts deviate from each other.\n",
    "\n",
    "http://www.math.uah.edu/stat/special/ChiSquare.html\n",
    "\n",
    "##### TF-idf(Term Frequency-Inverse Document Frequency)\n",
    "TF-idf16 is a weighting scheme, which measures how relevant a word to a sample in the dataset.The relevance\n",
    "increases when the number of times a word appears in the sample.\n",
    "\n",
    "Term Frequency is simplest approach is to\n",
    "assign the weight to be equal to the number\n",
    "of occurrences of term in document. Inverse frequency is measure of whether the\n",
    "term is common or rare across all documents.\n",
    "https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature weighting\n",
    "The features which are selected using feature selection criteria is weighted using Feature Presence(FP).We are\n",
    "calculating feature value by considering their presence or absence rather than count of feature in a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "###### Support Vector Machine \n",
    "to create classification model on features of different length, extracted\n",
    "from these sorted lists, in order to find the optimal feature length.SVM is capable of handling high dimensional data\n",
    "in a linearly or non-linearly manner.Although SVM takes times to create a classification model; it performs well for\n",
    "two class problems.\n",
    "\n",
    "###### Naïve-Bayes Classifier\n",
    "\n",
    "Naïve Bayes Multinomial distribution\n",
    "with Laplace Smoothing and Bernoulli\n",
    "distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Future Work\n",
    "\n",
    "Sentimental Lexicons, non-word\n",
    "tokens that are indicative of sentiments\n",
    "(i.e. emoticons) , capturing semantic\n",
    "similarities present in reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aim is to automatically mine these types of topics\n",
    "from the raw review text and to automatically assign sentiment\n",
    "labels to the relevant topics and review elements.\n",
    "\n",
    "we show how this\n",
    "can be used as the basis of a review recommendation system\n",
    "to automatically recommend high quality reviews even in the\n",
    "absence of any explicit helpfulness feedback.\n",
    "\n",
    "Review timeliness was also found to be important\n",
    "since review helpfulness declined as time went by.\n",
    "\n",
    "Just as it is useful to automate the filtering of helpful reviews\n",
    "it is also important to weed out malicious or biased\n",
    "reviews. These reviews can be well written and informative\n",
    "and so appear to be helpful. However these reviews often\n",
    "adopt a biased perspective that is designed to help or hinder\n",
    "sales of the target product. a reviewer's identity might be useful.\n",
    "\n",
    "use network analysis techniques\n",
    "to identify recurring spam in user generated comments associated\n",
    "with YouTube videos by identifying discriminating\n",
    "comment motifs that are indicative of spambots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classical review classification approach consider features relating to the ratings,\n",
    "structural, syntactic, and semantic properties of reviews to find ratings and review length among the most discriminating.\n",
    "Reviewer expertise was found to be a useful predictor of\n",
    "review helpfulness .People interested in a certain hostels are likely to pen high quality reviews for similar genre\n",
    "movies. \n",
    "\n",
    "Review timeliness was also found to be important\n",
    "since review helpfulness declined as time went by. \n",
    "\n",
    "Furthermore,\n",
    "opinion sentiment has been mined from user reviews to\n",
    "predict ratings and helpfulness in services.\n",
    "\n",
    "Just as it is useful to automate the filtering of helpful reviews\n",
    "it is also important to weed out malicious or biased\n",
    "reviews. These reviews can be well written and informative\n",
    "and so appear to be helpful. However these reviews often\n",
    "adopt a biased perspective that is designed to help or hinder\n",
    "sales of the target product . \n",
    "\n",
    "A machine learning approach to spam detection that\n",
    "is enhanced by information about the spammer’s identify as\n",
    "part of a two-tier co-learning approach. \n",
    "\n",
    "On a related topic, use network analysis techniques\n",
    "to identify recurring spam in user generated comments associated\n",
    "with reviews by identifying discriminating\n",
    "comment motifs that are indicative of spambots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Our model descibes techniques for mining topical and sentiment features from user generated reviews and demonstrate their ability to boost classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our focus is on automatically mining topics\n",
    "from user-generated product reviews and assigning sentiment\n",
    "to these topics on a per review basis.\n",
    "\n",
    "###### Topic Extraction\n",
    "\n",
    "We consider two basic types of topics—bi-grams and single\n",
    "nouns.\n",
    "\n",
    "To\n",
    "produce a set of bi-gram topics we extract all bi-grams from\n",
    "the global review set which conform to one of two basic partof-\n",
    "speech co-location patterns: (1) an adjective followed by a\n",
    "noun (AN) such as wide angle; and (2) a noun followed by a\n",
    "noun (NN) such as video mode. These are candidate topics\n",
    "that need to be filtered to avoid including AN’s that are actually\n",
    "opinionated single-noun topics; for example, excellent\n",
    "lens is a single-noun topic (lens) and not a bi-gram topic. To\n",
    "do this we exclude bi-grams whose adjective is found to be a\n",
    "sentiment word (e.g. excellent, good, great, lovely, terrible,\n",
    "horrible etc.) using the sentiment lexicon .\n",
    "\n",
    "To identify the single-noun topics we extract a candidate\n",
    "set of (non stop-word) nouns from the global review set. Often\n",
    "these single-noun candidates will not make for good topics;\n",
    "for example, they might include words such as family or\n",
    "day or vacation. A solution for\n",
    "validating such topics by eliminating those that are rarely associated\n",
    "with opinionated words. The intuition is that nouns\n",
    "that frequently occur in reviews and that are frequently associated\n",
    "with sentiment rich, opinion laden words are likely to\n",
    "be product topics that the reviewer is writing about, and therefore\n",
    "good topics. Thus, for each candidate single-noun, we\n",
    "calculate how frequently it appears with nearby words from\n",
    "a list of sentiment words , keeping the single-noun only if this\n",
    "frequency is greater than some threshold (in this case 70%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sentiment Analysis\n",
    "To determine the sentiment of the topics in the product topic\n",
    "set we use a method similar to the opinion pattern mining\n",
    "technique for extracting\n",
    "opinions from unstructured hostel reviews.\n",
    "\n",
    "Next we determine the part-of-speech tags for wmin, Ti\n",
    "and any words that occur between wmin and Ti. The POS\n",
    "sequence corresponds to an opinion pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once an entire pass of all topics has been completed we can compute the frequency of all opinion patterns that have been recorded. A pattern is deemed to be valid (from the perspective of our ability to assign sentiment) if it occurs more than the average number of occurrences over all patterns .\n",
    "For valid patterns we assign sentiment based on the sentiment of wmin and subject to whether Sj contains any negation terms within a 4-word-distance of wmin. If there are no such negation terms then the sentiment assigned to Ti in Sj is that of the sentiment word in the sentiment lexicon. If there is a negation word then this sentiment is reversed. If an opinion pattern is deemed not to be valid (based on its frequency) then we assign a neutral sentiment to each of its occurrences within the review set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To build a classifier for predicting review helpfulness we adopt a supervised machine learning approach. \n",
    "In the data\n",
    "that is available to us each review has a helpfulness score that\n",
    "reflects the percentage of positive votes that it has received, if\n",
    "any. In this work we label a review as helpful if and only if\n",
    "it has a helpfulness score in excess of 0.75. All other reviews\n",
    "are labeled as unhelpful.\n",
    "\n",
    "For each review Rk, we assign a collection of topics\n",
    "(topics(Rk) = T1, T2, ..., Tm) and corresponding sentiment\n",
    "scores (pos/neg/neutral) which can be considered in isolation\n",
    "and/or in aggregate as the basis for classification features.\n",
    "\n",
    "When it comes to sentiment we can formulate a variety of\n",
    "classification features from the number of positive (NumPos\n",
    "and NumUPos), negative (NumNeg and NumUNeg) and neutral\n",
    "(NumNeutral and NumUNeutral) topics (total and unique)\n",
    "in a review, to the rank-weighted number of positive (WPos),\n",
    "negative (WNeg), and neutral (WNeutral) topics, to the relative\n",
    "sentiment, positive (RelUPos), negative (RelUNeg), or\n",
    "neutral (RelUNeutral), of a review’s topics.\n",
    "\n",
    "We also include a measure of the relative density of opinionated\n",
    "(non-neutral sentiment) topics in a review and a relative measure of the difference between the\n",
    "overall review sentiment and the user’s normalized product\n",
    "rating, i.e. SignedRatingDiff(Rk) = RelUPos(Rk) −\n",
    "NormUserRating(Rk);\n",
    "\n",
    "To evaluate\n",
    "the ability of our classifier to make review recommendations\n",
    "we can use the classification confidence as one simple\n",
    "way to rank-order helpful reviews and select the top-ranked\n",
    "review for recommendation to the user.\n",
    "\n",
    "We can test the performance of these recommendation\n",
    "techniques because we know the actual\n",
    "helpfulness scores of all reviews (the ground-truth) we can\n",
    "compare the recommended review to the review which has\n",
    "the actual highest helpfulness score for each hostel, and average\n",
    "across all hostel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
